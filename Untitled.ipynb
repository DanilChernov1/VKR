{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa44b10-c883-4a9b-a297-845a86a9fd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:35:19.326294Z",
     "iopub.status.busy": "2025-04-24T03:35:19.325819Z",
     "iopub.status.idle": "2025-04-24T03:37:46.528174Z",
     "shell.execute_reply": "2025-04-24T03:37:46.527030Z",
     "shell.execute_reply.started": "2025-04-24T03:35:19.326260Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n",
      "Instruments: ['drums', 'bass', 'other', 'vocals']\n",
      "['CUDAExecutionProvider'] cuda:0\n",
      "Model load time: 1.16 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_001_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_002_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 141.76 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type htdemucs --use_onnx  --onnx_model_path onnx_models/htdemucs_bass.onnx  --config_path configs/config_musdb18_htdemucs.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e2e101-060b-41e8-9b6e-f43615469f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:38:05.620419Z",
     "iopub.status.busy": "2025-04-24T03:38:05.619392Z",
     "iopub.status.idle": "2025-04-24T03:40:30.415119Z",
     "shell.execute_reply": "2025-04-24T03:40:30.414088Z",
     "shell.execute_reply.started": "2025-04-24T03:38:05.620395Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n",
      "Instruments: ['drums', 'bass', 'other', 'vocals']\n",
      "['CUDAExecutionProvider'] cuda:0\n",
      "Model load time: 4.03 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_001_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_002_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 140.03 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type htdemucs --use_onnx  --onnx_model_path onnx_models/htdemucs_drums.onnx  --config_path configs/config_musdb18_htdemucs.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1440ec9e-25b2-4065-a2c9-355a52b74b29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:40:30.416918Z",
     "iopub.status.busy": "2025-04-24T03:40:30.416564Z",
     "iopub.status.idle": "2025-04-24T03:42:55.422093Z",
     "shell.execute_reply": "2025-04-24T03:42:55.421107Z",
     "shell.execute_reply.started": "2025-04-24T03:40:30.416896Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n",
      "Instruments: ['drums', 'bass', 'other', 'vocals']\n",
      "['CUDAExecutionProvider'] cuda:0\n",
      "Model load time: 4.05 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_001_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_002_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 140.93 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type htdemucs --use_onnx  --onnx_model_path onnx_models/htdemucs_other.onnx  --config_path configs/config_musdb18_htdemucs.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533aaff7-1307-4525-8f97-3c994ae14131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:42:55.423686Z",
     "iopub.status.busy": "2025-04-24T03:42:55.422983Z",
     "iopub.status.idle": "2025-04-24T03:45:19.997931Z",
     "shell.execute_reply": "2025-04-24T03:45:19.996932Z",
     "shell.execute_reply.started": "2025-04-24T03:42:55.423665Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n",
      "Instruments: ['drums', 'bass', 'other', 'vocals']\n",
      "['CUDAExecutionProvider'] cuda:0\n",
      "Model load time: 4.70 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_001_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_002_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 139.85 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type htdemucs --use_onnx  --onnx_model_path onnx_models/htdemucs_vocals.onnx  --config_path configs/config_musdb18_htdemucs.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153bbec6-42d6-4403-82fe-d823919bd8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:45:19.999760Z",
     "iopub.status.busy": "2025-04-24T03:45:19.999430Z",
     "iopub.status.idle": "2025-04-24T03:47:44.814851Z",
     "shell.execute_reply": "2025-04-24T03:47:44.813893Z",
     "shell.execute_reply.started": "2025-04-24T03:45:19.999740Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n",
      "Instruments: ['drums', 'bass', 'other', 'vocals']\n",
      "['CUDAExecutionProvider'] cuda:0\n",
      "Model load time: 4.71 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_001_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_002_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 140.08 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type htdemucs --use_onnx  --onnx_model_path onnx_models/htdemucs4.onnx  --config_path configs/config_musdb18_htdemucs.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a483343a-f3e6-40fd-98a2-f9a3c57ee659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T03:50:44.628015Z",
     "iopub.status.busy": "2025-04-24T03:50:44.627474Z",
     "iopub.status.idle": "2025-04-24T04:08:52.410145Z",
     "shell.execute_reply": "2025-04-24T04:08:52.408846Z",
     "shell.execute_reply.started": "2025-04-24T03:50:44.627990Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n",
      "GPU Compute Capability equal or above 8.0, using flash attention if input tensor is on cuda\n",
      "Instruments: ['vocals', 'other']\n",
      "['CUDAExecutionProvider'] cuda:0\n",
      "Model load time: 4.55 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_001_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_002_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1078.69 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type bs_roformer --use_onnx  --onnx_model_path onnx_models/bs_roformer.onnx  --config_path configs/model_bs_roformer.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c5697f-47aa-47f9-b44b-c8c149947a60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T04:08:52.411810Z",
     "iopub.status.busy": "2025-04-24T04:08:52.411317Z",
     "iopub.status.idle": "2025-04-24T04:08:52.515456Z",
     "shell.execute_reply": "2025-04-24T04:08:52.514385Z",
     "shell.execute_reply.started": "2025-04-24T04:08:52.411789Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._custom_ops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/work/resources/VKR/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mproc_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/resources/VKR/inference.py\u001b[0m in \u001b[0;36mproc_folder\u001b[0;34m(dict_args)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/VKR/utils.py\u001b[0m in \u001b[0;36mget_model_from_config\u001b[0;34m(model_type, config_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'segm_models'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegm_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSegm_Models_Net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegm_Models_Net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'torchseg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/VKR/models/segm_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msegmentation_models_pytorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprefer_target_instrument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/segmentation_models_pytorch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_zoo\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresnet_encoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/timm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_scriptable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_exportable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_scriptable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_exportable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_modules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_entrypoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mis_model_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_pretrained_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_pretrained_cfg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/timm/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mattention_pool2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttentionPool2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRotAttentionPool2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRotaryEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mblur_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlurPool2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_aa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifierHead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormMlpClassifierHead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClNormMlpClassifierHead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcond_conv2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCondConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_condconv_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_exportable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_scriptable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_no_jit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fused_attn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/timm/layers/classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0madaptive_avgmax_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectAdaptivePool2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcreate_act\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_act_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcreate_norm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_norm_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/timm/layers/create_norm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroupNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGroupNorm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRmsNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRmsNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleNorm2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m _NORM_MAP = dict(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_custom_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._custom_ops'"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type segm_models --use_onnx  --onnx_model_path onnx_models/segm_model.onnx  --config_path configs/config_vocals_segm_models.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3e0202-1038-4510-a371-a39b4206bb47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T04:08:52.516784Z",
     "iopub.status.busy": "2025-04-24T04:08:52.516466Z",
     "iopub.status.idle": "2025-04-24T04:10:04.311043Z",
     "shell.execute_reply": "2025-04-24T04:10:04.310012Z",
     "shell.execute_reply.started": "2025-04-24T04:08:52.516764Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n",
      "Instruments: ['vocals', 'other']\n",
      "['CUDAExecutionProvider'] cuda:0\n",
      "Model load time: 1.05 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_001_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_002_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 70.73 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type htdemucs --use_onnx  --onnx_model_path onnx_models/vocal_htdemucs.onnx  --config_path configs/config_vocals_htdemucs.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f970f-8abd-44b8-b4e7-47dfe726eb2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T04:10:04.313004Z",
     "iopub.status.busy": "2025-04-24T04:10:04.312654Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, use --force_cpu to disable it.\n",
      "Using device:  cuda:0\n",
      "Instruments: ['vocals', 'other']\n",
      "['CUDAExecutionProvider'] cuda:0\n",
      "Model load time: 10.69 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio chunks:  32%|███▏      | 979200/3037680 [01:19<02:47, 12313.82it/s]"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type mdx23c --use_onnx  --onnx_model_path onnx_models/mdx23c.onnx  --config_path configs/config_vocals_mdx23c.yaml  --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ab1ed-44e4-4e00-9afe-391a153b8656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a6760-bc73-4ef3-a471-a70a718ad041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3f431-92fc-4fca-975f-7ee71c74bb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e189d-bb2e-469c-a871-fed3a3e256c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433fc0fb-b9a8-47fb-9fcb-064f94e7cc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d03a1-6b42-4981-bed9-e2dc34bad01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:49:45.986574Z",
     "iopub.status.busy": "2025-04-22T17:49:45.982912Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cpu\n",
      "Start from checkpoint: results/HTDemucs4_FT_Bass.th\n",
      "Instruments: ['drums', 'bass', 'other', 'vocals']\n",
      "Model load time: 0.47 sec\n",
      "Total files found: 100. Using sample rate: 44100\n",
      "Processing track: input/wavs/song_000_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:   0%|          | 0/3373650 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 2048, 474]) torch.Size([8, 2, 485100])\n",
      "torch.Size([8, 16, 2048, 474]) torch.Size([8, 8, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  29%|██▉       | 970200/3373650 [00:34<01:26, 27855.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 2048, 474]) torch.Size([8, 2, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  54%|█████▍    | 1819125/3373650 [00:44<00:55, 27855.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 2048, 474]) torch.Size([8, 8, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  58%|█████▊    | 1940400/3373650 [00:50<00:35, 40869.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 2048, 474]) torch.Size([8, 2, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  83%|████████▎ | 2789325/3373650 [01:04<00:14, 40869.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 2048, 474]) torch.Size([8, 8, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  86%|████████▋ | 2910600/3373650 [01:06<00:09, 48315.99it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 2048, 474]) torch.Size([4, 2, 485100])\n",
      "torch.Size([4, 16, 2048, 474]) torch.Size([4, 8, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  97%|█████████▋| 3274425/3373650 [01:24<00:02, 48315.99it/s]\u001b[A\n",
      "Processing audio chunks: 3395700it [01:24, 40130.39it/s]                             \u001b[A\n",
      "                                                        \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_001_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:   0%|          | 0/3373650 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 2048, 474]) torch.Size([8, 2, 485100])\n",
      "torch.Size([8, 16, 2048, 474]) torch.Size([8, 8, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  29%|██▉       | 970200/3373650 [00:15<00:38, 62221.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 2048, 474]) torch.Size([8, 2, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  54%|█████▍    | 1819125/3373650 [00:27<00:24, 62221.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 2048, 474]) torch.Size([8, 8, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  58%|█████▊    | 1940400/3373650 [00:30<00:22, 63804.80it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 2048, 474]) torch.Size([8, 2, 485100])\n",
      "torch.Size([8, 16, 2048, 474]) torch.Size([8, 8, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:  86%|████████▋ | 2910600/3373650 [00:45<00:07, 63675.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 2048, 474]) torch.Size([4, 2, 485100])\n",
      "torch.Size([4, 16, 2048, 474]) torch.Size([4, 8, 485100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks: 3395700it [00:53, 63241.15it/s]                             \u001b[A\n",
      "                                                        \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: input/wavs/song_002_mixture.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing audio chunks:   0%|          | 0/3373650 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 2048, 474]) torch.Size([8, 2, 485100])\n"
     ]
    }
   ],
   "source": [
    "%run -i inference.py --model_type htdemucs  --config_path configs/config_musdb18_htdemucs.yaml --start_check_point results/HTDemucs4_FT_Bass.th --input_folder input/wavs/  --store_dir separation_results2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d2ca3b-6857-4277-8555-8e1d2530740d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T17:16:40.483487Z",
     "iopub.status.busy": "2025-04-22T17:16:40.480103Z",
     "iopub.status.idle": "2025-04-22T17:16:40.854145Z",
     "shell.execute_reply": "2025-04-22T17:16:40.853249Z",
     "shell.execute_reply.started": "2025-04-22T17:16:40.483418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_model_from_config\n",
    "model, config = get_model_from_config('htdemucs', 'configs/config_musdb18_htdemucs.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72629c1e-12cf-4c24-9bd3-35a0f36a6e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:49:52.025168Z",
     "iopub.status.busy": "2025-04-22T15:49:52.024208Z",
     "iopub.status.idle": "2025-04-22T15:49:52.196862Z",
     "shell.execute_reply": "2025-04-22T15:49:52.196123Z",
     "shell.execute_reply.started": "2025-04-22T15:49:52.025140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cpu\"\n",
    "state_dict = torch.load('results/model_vocals_htdemucs.ckpt', map_location=device, weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae9bcb2-03f6-4ff1-9340-80d67145ddfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:49:52.198454Z",
     "iopub.status.busy": "2025-04-22T15:49:52.197759Z",
     "iopub.status.idle": "2025-04-22T15:49:52.210584Z",
     "shell.execute_reply": "2025-04-22T15:49:52.209985Z",
     "shell.execute_reply.started": "2025-04-22T15:49:52.198431Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'state' in state_dict:\n",
    "    state_dict = state_dict['state']\n",
    "# Fix for apollo pretrained models\n",
    "if 'state_dict' in state_dict:\n",
    "    state_dict = state_dict['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9a545f-7f46-4f31-a805-65ed63ab71b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:49:52.212560Z",
     "iopub.status.busy": "2025-04-22T15:49:52.211933Z",
     "iopub.status.idle": "2025-04-22T15:49:52.271398Z",
     "shell.execute_reply": "2025-04-22T15:49:52.270620Z",
     "shell.execute_reply.started": "2025-04-22T15:49:52.212538Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7378367c-9b76-4b46-a364-6992f1cac544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:49:52.272987Z",
     "iopub.status.busy": "2025-04-22T15:49:52.272281Z",
     "iopub.status.idle": "2025-04-22T15:49:52.291193Z",
     "shell.execute_reply": "2025-04-22T15:49:52.290525Z",
     "shell.execute_reply.started": "2025-04-22T15:49:52.272964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_model_to_onnx(model, input_tensor, input_tensor2, onnx_output_file):\n",
    "    \n",
    "    model.eval()\n",
    "    print(model)\n",
    "    torch.onnx.export(\n",
    "        model, \n",
    "        (input_tensor,\n",
    "        input_tensor2),\n",
    "        onnx_output_file,\n",
    "        input_names = ['input1', 'input2'],   # Имя выходного тензора\n",
    "        output_names=['output1', 'output2'],\n",
    "        dynamic_axes={\n",
    "            'input1': {0: 'batch_size'},\n",
    "            'input2': {0: 'batch_size'},\n",
    "            'output1': {0: 'batch_size'},\n",
    "            'output2': {0: 'batch_size'},\n",
    "        },\n",
    "        verbose = True)\n",
    "\n",
    "    print(f\"Model has been exported to {onnx_output_file}\") \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08cf0b09-4163-41ce-885f-cb68056d99d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:49:52.292931Z",
     "iopub.status.busy": "2025-04-22T15:49:52.292048Z",
     "iopub.status.idle": "2025-04-22T15:49:52.310491Z",
     "shell.execute_reply": "2025-04-22T15:49:52.309855Z",
     "shell.execute_reply.started": "2025-04-22T15:49:52.292902Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c45c918-2751-4472-a7df-bdaba3eac79d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T15:52:17.564277Z",
     "iopub.status.busy": "2025-04-22T15:52:17.562800Z",
     "iopub.status.idle": "2025-04-22T15:52:29.086549Z",
     "shell.execute_reply": "2025-04-22T15:52:29.084932Z",
     "shell.execute_reply.started": "2025-04-22T15:52:17.564216Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTDemucs(\n",
      "  (encoder): ModuleList(\n",
      "    (0): HEncLayer(\n",
      "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
      "      (norm1): Identity()\n",
      "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (norm2): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): HEncLayer(\n",
      "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
      "      (norm1): Identity()\n",
      "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (norm2): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): HEncLayer(\n",
      "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
      "      (norm1): Identity()\n",
      "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (norm2): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): HEncLayer(\n",
      "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
      "      (norm1): Identity()\n",
      "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (norm2): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ModuleList(\n",
      "    (0): HDecLayer(\n",
      "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
      "      (norm2): Identity()\n",
      "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm1): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): HDecLayer(\n",
      "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
      "      (norm2): Identity()\n",
      "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm1): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): HDecLayer(\n",
      "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
      "      (norm2): Identity()\n",
      "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm1): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): HDecLayer(\n",
      "      (conv_tr): ConvTranspose2d(48, 8, kernel_size=(8, 1), stride=(4, 1))\n",
      "      (norm2): Identity()\n",
      "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm1): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tencoder): ModuleList(\n",
      "    (0): HEncLayer(\n",
      "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "      (norm1): Identity()\n",
      "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
      "      (norm2): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): HEncLayer(\n",
      "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "      (norm1): Identity()\n",
      "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
      "      (norm2): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): HEncLayer(\n",
      "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "      (norm1): Identity()\n",
      "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
      "      (norm2): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): HEncLayer(\n",
      "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
      "      (norm1): Identity()\n",
      "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
      "      (norm2): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (tdecoder): ModuleList(\n",
      "    (0): HDecLayer(\n",
      "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
      "      (norm2): Identity()\n",
      "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (norm1): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(384, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(48, 768, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): HDecLayer(\n",
      "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
      "      (norm2): Identity()\n",
      "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (norm1): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(192, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(24, 384, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): HDecLayer(\n",
      "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
      "      (norm2): Identity()\n",
      "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (norm1): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(96, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(12, 192, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): HDecLayer(\n",
      "      (conv_tr): ConvTranspose1d(48, 4, kernel_size=(8,), stride=(4,))\n",
      "      (norm2): Identity()\n",
      "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (norm1): Identity()\n",
      "      (dconv): DConv(\n",
      "        (layers): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (0): Conv1d(48, 6, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
      "            (1): GroupNorm(1, 6, eps=1e-05, affine=True)\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv1d(6, 96, kernel_size=(1,), stride=(1,))\n",
      "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
      "            (5): GLU(dim=1)\n",
      "            (6): LayerScale()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (freq_emb): ScaledEmbedding(\n",
      "    (embedding): Embedding(512, 48)\n",
      "  )\n",
      "  (channel_upsampler): Conv1d(384, 512, kernel_size=(1,), stride=(1,))\n",
      "  (channel_downsampler): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "  (channel_upsampler_t): Conv1d(384, 512, kernel_size=(1,), stride=(1,))\n",
      "  (channel_downsampler_t): Conv1d(512, 384, kernel_size=(1,), stride=(1,))\n",
      "  (crosstransformer): CrossTransformerEncoder(\n",
      "    (norm_in): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm_in_t): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (layers): ModuleList(\n",
      "      (0): MyTransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "      )\n",
      "      (1): CrossTransformerEncoderLayer(\n",
      "        (cross_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (2): MyTransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "      )\n",
      "      (3): CrossTransformerEncoderLayer(\n",
      "        (cross_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (4): MyTransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "      )\n",
      "    )\n",
      "    (layers_t): ModuleList(\n",
      "      (0): MyTransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "      )\n",
      "      (1): CrossTransformerEncoderLayer(\n",
      "        (cross_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (2): MyTransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "      )\n",
      "      (3): CrossTransformerEncoderLayer(\n",
      "        (cross_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (4): MyTransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (norm_out): MyGroupNorm(1, 512, eps=1e-05, affine=True)\n",
      "        (gamma_1): LayerScale()\n",
      "        (gamma_2): LayerScale()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Model has been exported to vocal_htdemucs.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input_tensor1 = torch.randn(1, 4, 2048, 474).to('cpu')\n",
    "input_tensor2 = torch.randn(1, 2, 485100).to('cpu')\n",
    "onnx = export_model_to_onnx(model, input_tensor1, input_tensor2, \"vocal_htdemucs.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94acb2-2e16-4841-bb64-1c8f9ffbe114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef049b90-b1f0-4e1b-921d-fa65f8bee4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
